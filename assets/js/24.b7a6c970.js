(window.webpackJsonp=window.webpackJsonp||[]).push([[24],{478:function(t,a,e){"use strict";e.r(a);var r=e(28),s=Object(r.a)({},(function(){var t=this,a=t.$createElement,e=t._self._c||a;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h2",{attrs:{id:"简要概况react的主要贡献和核心思想"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#简要概况react的主要贡献和核心思想"}},[t._v("#")]),t._v(" 简要概况ReAct的主要贡献和核心思想?")]),t._v(" "),e("p",[t._v("ReAct范式的核心贡献在于它巧妙地解决了一个关键矛盾，即大型语言模型内在的推理能力与外在的行动能力之间长期存在的割裂问题。在此之前，模型要么像一位闭门造车的学者，仅凭内部知识进行思维链式的推理，这虽然逻辑清晰但容易脱离实际，产生所谓的幻觉；要么像一个缺乏计划的执行者，能够执行搜索等动作，却因缺乏高层指导而在复杂任务重迷失方向。ReAct的革命性在于提出了一种协同机制，让模型能够以交错的方式进行思考和行动。这模仿了人类解决问题的方式：我们先在内心制定计划、进行推理，然后根据计划采取行动，再根据行动带来的反馈调整我们的思考和行动。这模仿了人类解决问题的方式：我们先在内心制定计划、进行推理、然后根据计划采取行动，再根据行动带来的反馈调整我们的思考。这种”思考-行动-在思考“的闭环，使得模型的问题解决过程变得更加grounded,也就是更基于事实，同时也打打增强了其决策的可解释性。因为我们能清晰地看到模型的思考轨迹。")]),t._v(" "),e("h2",{attrs:{id:"描述一下react模型在解决一个实际问题时的完整动态过程"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#描述一下react模型在解决一个实际问题时的完整动态过程"}},[t._v("#")]),t._v(" 描述一下ReAct模型在解决一个实际问题时的完整动态过程？")]),t._v(" "),e("p",[t._v('ReAct工作流程详解：\n第一阶段：任务解析与初步规划：模型在接受到问题-"科罗拉多造山带东段延伸区域的海报范围是多少？"-之后，并不会立即行动。相反，它首先会进行任务解析。\n第二阶段：迭代式信息检索与推理引导：这是ReAct循环的核心。模型不会一次性规划所有步骤，而是根据上一步的观察结果动态调整。\n- 行动1与观察：基于初始规划，模型执行第一个行动：Search[Colorado orogeny]。环境返回观察结果。\n- 推理1与行动2：模型并非简单地读取整个文本，而是进行关键信息提取与推理。它会分析返回的文本进行思考：描述中提到了东段这个概念，但没有给出详细说明。因此，我需要专门在这个页面内搜索“eastern sector”以获取更精确的信息。“这直接引导至下一个行动：Lookup[eastern sector]')]),t._v(" "),e("ul",[e("li",[t._v('第三阶段：信息验证与答案合成：当行动Search[High Plains]成功检索到海拔数据"从1800到7000英尺"时，模型进入最终阶段。\n'),e("ul",[e("li",[t._v("最终推理与决策：模型会进行答案验证，思考：检索到的数据直接、明确地回答了原始问题。信息是完整的，可以得出结论了。”")]),t._v(" "),e("li",[t._v("终止行动：基于此最终推理：模型触发终止行动：Finsh[1800 to 7000 ft]，提交答案并结束任务。")])])])]),t._v(" "),e("h2",{attrs:{id:"react这种协同方式在实际任务如知识问答和交互决策任务上-与传统方法相比表现如何"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#react这种协同方式在实际任务如知识问答和交互决策任务上-与传统方法相比表现如何"}},[t._v("#")]),t._v(" ReAct这种协同方式在实际任务如知识问答和交互决策任务上，与传统方法相比表现如何？")]),t._v(" "),e("p",[t._v("总体来说，ReAct展现了显著且一致的优越性，但同时也凸显了一些内在的挑战。\n优势：")]),t._v(" "),e("ul",[e("li",[t._v("提升了模型的事实可靠性和可解释性。\n挑战:")]),t._v(" "),e("li",[t._v("推理的灵活性与错误恢复。")])]),t._v(" "),e("h2",{attrs:{id:"react与cot的混合方法-如react-cot-sc-。这种组合策略的动机是什么"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#react与cot的混合方法-如react-cot-sc-。这种组合策略的动机是什么"}},[t._v("#")]),t._v(" ReAct与CoT的混合方法(如ReAct -> CoT - SC) 。这种组合策略的动机是什么？")]),t._v(" "),e("p",[t._v('这种组合策略的根本冬季是认识到，无论是ReAct 还是CoT,都只是模拟了人类智能的一部分。一个真正强大的系统应该能够根据情境，灵活地利用"外部知识"和调用"内部知识"之间做出最佳选择。其冬季可以从以下几个层面来理解：')]),t._v(" "),e("ol",[e("li",[t._v("克服单一范式的固有缺陷")])]),t._v(" "),e("ul",[e("li",[t._v("ReAct的局限性：对环境的依赖与推理约束。如果搜索的关键词不当或数据库中没有相关信息，模型就是陷入搜索失败的困境，无法获取推理所需的关键事实。此外,ReAct的推理步骤被强制与行动和观察交叉在一起，这种步骤有时会限制其进行更自由、更复杂的逻辑推理，甚至可能导致模型在某个步骤陷入循环，无法跳出。")]),t._v(" "),e("li",[t._v("CoT的局限性：知识幻觉与时效性问题 CoT的优势在于能够流畅地进行逻辑推理，但它完全依赖于模型预训练时学到的内部知识。这带来了两个主要的问题：一是事实性幻觉，模型可能会基于其内部不准确或模型的记忆，自信地编造出错误的推理步骤和答案，二是知识时效性，模型无法获取训练数据截止时间之后的新信息，对于需要最新知识的问题无能为力。\n混合策略的动机正是为了创建一个安全网：当一种方法可能失效时，系统可以自动切换到另一种方法。")])]),t._v(" "),e("ol",{attrs:{start:"2"}},[e("li",[t._v("实现“外部验证”与“内部效率”的动态平衡：\n混合策略体现了一种动态资源分配的思想。")])]),t._v(" "),e("ul",[e("li",[t._v("ReAct -> CoT-SC的动机：当外部信息获取成本高或失败时，启用内部推理。这种路径的启发式规则是：如果ReAct在预设步数内(如5-7步)未能找到答案，则回退到CoT-SC。这样做的动机是追求效率。对于一些模型内部知识已经足够解决、或者通过简单推理能够得出答案的问题，强制进行多步搜索是低效的。当ReAct因环境限制而卡主时，及时切换到CoT-SC相当于说“好吧，既然从外面找不到答案，那就看看我们脑子里还记得什么，用集体智慧来投票选择一个最佳答案。”这节省了不必要的交互成本。")]),t._v(" "),e("li",[t._v("CoT-SC-> ReAcT的动机：当内部知识置信度低时，寻求外部证据 这种路径的规则是：如果CoT-SC多个样本中得票最高的答案未能超过半数(即模型内部知识无法给出高置信度的答案)，则回退到ReAct。其冬季是提高答案的准确性和事实准确性。当模型内心很犹豫，无法达成强烈共识时，这表明内部知识可能不足以可靠地解决问题。此时，主动启动ReAct去外部世界寻找确凿证据，是更负责任、更可靠的做法。")])]),t._v(" "),e("h2",{attrs:{id:"什么是plan-and-solve-prompting-ps-技术的核心思想及其解决的主要问题"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#什么是plan-and-solve-prompting-ps-技术的核心思想及其解决的主要问题"}},[t._v("#")]),t._v(" 什么是Plan-and-Solve-Prompting(PS) 技术的核心思想及其解决的主要问题？")]),t._v(" "),e("p",[t._v('Plan-and-Solve Prompting是一种创新的零样本提示方法，其核心思想是将复杂的推理过程明确划分为两个阶段：计划阶段和执行阶段。这种方法主要针对Zero-shot-CoT存在的三个关键问题：计算错误、步骤确实错误和语义理解错误。通过要求模型先制定解决问题的整体计划，再将计划分解为具体步骤执行，PS方法使推理过程更加结构化和可控。与简单的"让我们一步步思考"相比，PS方法引导模型进行更深层次的元认知活动，这类似于人类解决复杂问题时的思考方式，能够显著提高推理的准确性和完整性。')]),t._v(" "),e("h2",{attrs:{id:"ps-在基础ps版本上做了哪些重要改进-这些改进如何具体提升性能"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#ps-在基础ps版本上做了哪些重要改进-这些改进如何具体提升性能"}},[t._v("#")]),t._v(" PS+在基础PS版本上做了哪些重要改进？这些改进如何具体提升性能？")]),t._v(" "),e("p",[t._v("PS+版本在基础PS框架上引入了两个关键的细化指令。首先是明确要求:提取相关变量及其对应数值“，这一指令强制模型在推理初期就进行关键信息的识别和整理。其次是增加了计算中间结果的要求。这不仅强调计算准确性，还引入了常识性校验机制。")]),t._v(" "),e("h2",{attrs:{id:"为什么ps方法在数学推理任务上表现特别突出-而在其他类型任务上提升相对有限"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#为什么ps方法在数学推理任务上表现特别突出-而在其他类型任务上提升相对有限"}},[t._v("#")]),t._v(" 为什么PS方法在数学推理任务上表现特别突出，而在其他类型任务上提升相对有限？")]),t._v(" "),e("p",[t._v('这种性能差异源于不同推理任务的内在特性与PS方法优势的匹配程度。数学推理任务通常具有明确的结构化特征，问题中包含清晰的变量、数值和运算关系，这与PS方法"先计划后执行"的框架高度契合。模型可以自然地制定线性推理计划，并按步骤执行。相比之下，常识推理任务更多依赖深层的语义理解和背景知识，其推理路径往往是非线性的，PS方法虽然能优化推理过程的结构，但难以直接解决语义理解的根本性调整。这种差异正好说明了PS方法更适合优化具有明确步骤结构的推理任务。')]),t._v(" "),e("h2",{attrs:{id:"在实际应用中-设计有效的ps提示词需要注意哪些关键要素"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#在实际应用中-设计有效的ps提示词需要注意哪些关键要素"}},[t._v("#")]),t._v(" 在实际应用中，设计有效的PS提示词需要注意哪些关键要素？")]),t._v(" "),e("p",[t._v("设计高质量的PS提示词需要重点关注三个要素：指令的具体性、任务的适配性和验证机制的完整性。首先，指令必须足够具体，避免模糊表述。其次，提示词需要与具体任务特性相匹配。最重要的是，应该考虑引入某种形式的验证机制，比如要求模型在完成推理后进行自我检查，或者从不同角度验证结果的合理性，这有助于发现潜在的逻辑漏洞户理解偏差。")])])}),[],!1,null,null,null);a.default=s.exports}}]);